{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55903a99-516b-44ec-aa07-27107687b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/config.json...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/eval_results.txt...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/merges.txt...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/model_args.json...\n",
      "- [4 files][449.2 KiB/449.2 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/optimizer.pt...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/pytorch_model.bin...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/scheduler.pt...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/special_tokens_map.json...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/tokenizer_config.json...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/training_args.bin...\n",
      "Copying gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model/vocab.json...\n",
      "/ [11 files][  1.6 GiB/  1.6 GiB]    7.2 MiB/s                                  \n",
      "Operation completed over 11 objects/1.6 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://internal.whitehead.ai/daily-dialog/01-24-2022_09_23_11/outputs/best_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338923d3-f7b6-4000-bee0-a2ae5af5c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch datasets transformers pandas tensorflow > /dev/null 2>&1\n",
    "!pip install --upgrade wandb simpletransformers tensorflow > /dev/null 2>&1 || pip install --user --upgrade tensorflow wandb simpletransformers > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eadac65d-e10f-40fb-9be9-6849b96b501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFDebertaForSequenceClassification\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "\n",
    "model = ClassificationModel(\"deberta\", \"./best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2867ec-2540-4a62-8253-462dc4ae20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 02:23:25.049291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 02:23:25.050418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 02:23:25.595210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-02-02 02:23:25.687869: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-02 02:23:25.734819: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaForSequenceClassification: ['deberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDebertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFDebertaForSequenceClassification.from_pretrained(\"./best_model\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ef71e9-aea9-4e0a-ae7e-ab881a8a6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(\"./best_model_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ebcf0-a486-4594-8f59-bf8b9ced0def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:latest"
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
